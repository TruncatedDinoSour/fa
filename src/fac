#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Fa programming language"""

import os
import sys
from dataclasses import dataclass
from enum import Enum, auto
from typing import Any, Dict, Generator, Iterable, List, Optional, Tuple
from warnings import filterwarnings as filter_warnings


class TokenType(Enum):
    PUSH_INT = auto()
    PUSH_STR = auto()
    MUTABILITY = auto()
    SYS = auto()
    DROP = auto()
    SWAP = auto()
    MACRO = auto()
    END = auto()
    EXPAND_MACRO = auto()
    INCLUDE = auto()


class Mutability(Enum):
    RW = auto()
    RO = auto()


@dataclass
class Token:
    ttype: Optional[TokenType]
    tvalue: Any
    tpos: Tuple[str, int, int]  # file, line, ip

    def __str__(self) -> str:
        if self.ttype is None:
            return self.__repr__()

        return f"Token at position {':'.join(map(str, self.tpos))!r} \
{self.ttype.name!r} with value {self.tvalue!r}"


EXIT_OK: int = 0
EXIT_ER: int = 1
NULL_TOKEN: Token = Token(None, None, ("", 0, 0))
ANOTATION_CONF: Dict[str, bool] = {"enabled": True}

ASM_SNIPPETS: Dict[str, Dict[str, Tuple[str, ...]]] = {
    "nasm-x86_64-linux": {
        "registers": (
            "rax",
            "rdi",
            "rsi",
            "rdx",
            "r8",
            "r9",
            "r10",
            "r11",
            "r12",
            "r13",
            "r14",
            "r15",
        )
    }
}

MACROS: Dict[str, List[Token]] = {}


def error(msg: str, token: Token = NULL_TOKEN) -> None:
    print(f"ERROR: {':'.join(map(str, token.tpos))}: {msg}", file=sys.stderr)
    sys.exit(EXIT_ER)


def make_usable_asm(asm: Iterable[str]) -> Generator[Tuple[str, Token], None, None]:
    yield from ((line, NULL_TOKEN) for line in asm)


def anotate_assembly(
    assembly: Generator[Tuple[str, Token], None, None], comment_char: str
) -> Generator[str, None, None]:
    log("Anotating assembly")

    for asm in assembly:
        if asm[1] == NULL_TOKEN or not ANOTATION_CONF["enabled"]:
            yield asm[0]
            continue

        yield f"    {asm[0]}  {comment_char} {asm[1]}"


def parse_string(string: str, token: Token) -> Generator[int, None, None]:
    ip: int = 0

    while ip < len(string):
        char: str = string[ip]

        if char == "\\":
            ip += 1
            char = string[ip]

            if char == "n":
                yield 10
            elif char == "t":
                yield 9
            elif char == "b":
                yield 8
            elif char == "f":
                yield 12
            elif char == "r":
                yield 13
            elif char == "{":
                _code: str = ""

                ip += 1
                char = string[ip]

                while char != "}":
                    _code += char
                    ip += 1
                    char = string[ip]

                if not _code:
                    error("Empty escape code", token)

                yield int(_code)
            else:
                yield ord(char)
        else:
            yield ord(char)

        ip += 1


def fa_to_ast(fa: str, line: int, file: str = "") -> Generator[Token, None, None]:
    words: List[str] = fa.split(" ")
    ip: int = 0

    def make_token(ttype: TokenType, tvalue: Any) -> Token:
        return Token(ttype, tvalue, (file, line, ip))

    while ip < len(words):
        word: str = words[ip].strip()
        old_ip: int = ip
        _position: str = ":".join(map(str, (file, line, ip)))

        if not word:
            ip += 1
            continue

        if word.startswith("--"):
            break

        if word.startswith('"'):
            _tmp_str: List[str] = [word]

            while not word.endswith('"'):
                ip += 1
                try:
                    word = words[ip].strip()
                except IndexError:
                    error(
                        f"Unclosed string at position {_position} at file {file!r} \
(starting at IP {old_ip})",
                    )

                _tmp_str.append(word)

            yield make_token(
                TokenType.PUSH_STR,
                " ".join(_tmp_str)[1:-1],
            )
        elif word.isnumeric():
            yield make_token(TokenType.PUSH_INT, int(word))
        elif word.startswith("%"):
            yield make_token(TokenType.EXPAND_MACRO, word[1:])
        elif word == "rw":
            yield make_token(TokenType.MUTABILITY, Mutability.RW)
        elif word == "ro":
            yield make_token(TokenType.MUTABILITY, Mutability.RO)
        elif word == "sys":
            ip += 1
            word = words[ip]

            yield make_token(TokenType.SYS, int(word))
        elif word == "drop":
            yield make_token(TokenType.DROP, None)
        elif word == "swap":
            yield make_token(TokenType.SWAP, None)
        elif word == "macro":
            ip += 1
            word = words[ip].strip()

            yield make_token(TokenType.MACRO, word)
        elif word == "end":
            yield make_token(TokenType.END, None)
        elif word == "include":
            _include_file: List[str] = []

            ip += 1
            word = words[ip].strip()

            if not word.startswith("'"):
                error("Include must start with '")

            _include_file.append(word[1:])

            while not word.endswith("'"):
                ip += 1
                word = words[ip].strip()
                _include_file.append(word)

            yield make_token(TokenType.INCLUDE, " ".join(_include_file)[:-1])
        else:
            error(
                f"Unexpected word {word!r} at position {_position} at file {file!r} while generating AST",
            )

        ip += 1


def generate_assembly_linux_x86_64_nasm(
    ast: Tuple[Token, ...],
) -> Generator[Tuple[str, Token], None, None]:
    log("Making generator for Linux x86_64 nasm assembly from AST")

    ip: int = 0

    yield from make_usable_asm(("BITS 64", "global _start"))

    start_lb: List[Tuple[str, Token]] = []
    data_lb: List[Tuple[str, Token]] = []
    rodata_lb: List[Tuple[str, Token]] = []

    tmp_stack: List[Any] = []

    while ip < len(ast):
        token: Token = ast[ip]
        old_ip: int = ip

        if token.ttype is None:
            error("Null token detected", token)
            break  # Because some linters are assholes

        tname: str = f"fa_{token.ttype.name}_{ip}_{len(start_lb) + len(data_lb) + len(rodata_lb)}"

        if token.ttype == TokenType.PUSH_INT:
            start_lb.append((f"push {token.tvalue}", token))
            tmp_stack.append(token.tvalue)
        elif token.ttype == TokenType.PUSH_STR:
            parsed_string_codes: Tuple[int, ...] = tuple(
                parse_string(token.tvalue, token)
            ) or (0,)

            ip += 1
            token = ast[ip]

            str_data_lb: List[Tuple[str, Token]]

            if token.tvalue == Mutability.RW:
                str_data_lb = data_lb
            elif token.tvalue == Mutability.RO:
                str_data_lb = rodata_lb
            else:
                error("Unknown mutability context for string", token)

            str_data_lb.extend(
                (
                    (
                        f"str_{tname}: db {','.join(map(str, parsed_string_codes))}",
                        ast[old_ip],
                    ),
                    (f"strlen_{tname}: equ $-str_{tname}", ast[old_ip]),
                )
            )

            start_lb.extend(
                (
                    (f"push strlen_{tname}", ast[old_ip]),
                    (f"push str_{tname}", ast[old_ip]),
                )
            )

            _tmp_str: str = "".join(chr(charcode) for charcode in parsed_string_codes)
            tmp_stack.extend((len(_tmp_str), _tmp_str))
        elif token.ttype == TokenType.MUTABILITY:
            error(
                "Mutability must not be parsed \
outside of word context",
                token,
            )
        elif token.ttype == TokenType.SYS:
            start_lb.extend(
                (f"pop {ASM_SNIPPETS['nasm-x86_64-linux']['registers'][reg]}", token)
                for reg in range(token.tvalue)
            )
            start_lb.extend((("syscall", token), ("push rax", token)))

            # Syscall always returns
            tmp_stack.append(0)
        elif token.ttype == TokenType.DROP:
            start_lb.extend(
                (
                    ("pop rax", token),
                    ("imul rax, 8", token),
                    ("add rsp, rax", token),
                )
            )
            tmp_stack.pop()
        elif token.ttype == TokenType.SWAP:
            start_lb.extend(
                (
                    ("pop rax", token),
                    ("pop rdi", token),
                    ("push rax", token),
                    ("push rdi", token),
                )
            )

            tmp_stack.extend((tmp_stack.pop(), tmp_stack.pop()))
        else:
            error(f"Unexpected {token}", token)

        ip += 1

    yield from make_usable_asm(("segment .text", "_start:"))
    yield from start_lb

    if data_lb:
        yield "segment .data", NULL_TOKEN
        yield from data_lb

    if rodata_lb:
        yield "segment .rodata", NULL_TOKEN
        yield from rodata_lb


def file_to_ast(file: str) -> Generator[Token, None, None]:
    log(f"Generating ast for {file!r}")

    with open(file, "r") as fa_code:
        for line_num, line in enumerate(fa_code):
            if not line:
                continue

            yield from fa_to_ast(line, line_num, file)


def print_help() -> int:
    def ep(msg: str) -> None:
        sys.stderr.write(f" :: {msg}\n")

    help_page: Tuple[str, ...] = (
        "Usage:",
        f"   {sys.argv[0]} <file|-help> [flags...]",
        "Flags:",
        "   -no-anotate                                 Doesn't anotate assembly",
        "   -asm-flags <flag,flag,flag,...>             Sets assembly flags",
        "   -ld-flags <flag,flag,flag,...>              Sets linker flags",
        "   -help                                       Prints help",
        "",
    )

    sys.stderr.write("\n".join(help_page))

    return EXIT_ER


def parse_flags(flags: List[str]) -> Dict[str, Any]:
    ip: int = 0

    flagd: Dict[str, Any] = {
        "anotate": True,
        "asm-flags": "",
        "ld-flags": "",
        "output": os.path.basename(os.path.splitext(sys.argv[1])[0]),
    }

    if not flags:
        return flagd

    while ip < len(flags):
        flag: str = flags[ip]

        if flag == "-no-anotate":
            flagd["anotate"] = False
        elif flag == "-asm-flags":
            ip += 1

            if ip >= len(flags):
                error("Missing comma-seperated flags to -asm-flags")

            flag = flags[ip]

            flagd["asm-flags"] = flag.split(",")
        elif flag == "-ld-flags":
            ip += 1

            if ip >= len(flags):
                error("Missing comma-seperated flags to -ld-flags")

            flag = flags[ip]

            flagd["ld-flags"] = flag.split(",")
        elif flag == "-help":
            sys.exit(print_help())
        elif flag == "-o":
            ip += 1

            if ip >= len(flags):
                error("Missing output file to -o")

            flag = flags[ip]

            flagd["output"] = flag
        else:
            error(f"Unknown flag {flag!r}")

        ip += 1

    return flagd


def log(msg: str) -> None:
    print(f" :: {msg}")


def run_command_log(cmd: str) -> None:
    log(f"Running: {cmd}")

    if os.system(cmd):
        error("Command failed")


def preprocess_ast(ast: Tuple[Token, ...], logging: bool = False) -> Generator[Token, None, None]:
    if logging:
        log("Preprocessing AST")

    ip: int = 0

    while ip < len(ast):
        token: Token = ast[ip]

        if token.ttype == TokenType.MACRO:
            macro_body = []
            macro_name = token.tvalue

            while token.ttype != TokenType.END:
                ip += 1
                token = ast[ip]
                macro_body.append(token)

            macro_body.pop()  # Removes 'end'
            MACROS[macro_name] = list(preprocess_ast(tuple(macro_body)))
        elif token.ttype == TokenType.EXPAND_MACRO:
            if token.tvalue not in MACROS:
                error(f"Cannot expand undefined macro {token.tvalue!r}")

            yield from preprocess_ast(tuple(MACROS[token.tvalue]))
        elif token.ttype == TokenType.INCLUDE:
            yield from preprocess_ast(tuple(file_to_ast(token.tvalue)))
        else:
            yield token

        ip += 1


def main() -> int:
    """Entry/main function"""

    if len(sys.argv) < 2:
        return print_help()
    elif sys.argv[1] == "-help":
        print_help()
        return 0
    elif not os.path.isfile(sys.argv[1]):
        error(f"{sys.argv[1]!r}: No such file")

    flags: Dict[str, Any] = parse_flags(sys.argv[2:])

    if not flags["anotate"]:
        ANOTATION_CONF["enabled"] = False

    bin_name: str = flags["output"]
    asm_name: str = f"{bin_name}.asm"
    obj_name: str = f"{bin_name}.o"

    with open(asm_name, "w") as asm_file:
        file_ast: Tuple[Token, ...] = tuple(file_to_ast(sys.argv[1]))

        preprocessed_ast: Tuple[Token, ...] = tuple(preprocess_ast(file_ast, True))

        nasm_assembly: Generator[
            Tuple[str, Token], None, None
        ] = generate_assembly_linux_x86_64_nasm(preprocessed_ast)

        anotated_nasm_assembly: Generator[str, None, None] = anotate_assembly(
            nasm_assembly, ";"
        )

        log(f"Writting assembly to {asm_file.name!r}")
        asm_file.write("\n".join(anotated_nasm_assembly))

    run_command_log(
        f"nasm -felf64 -o {obj_name!r} {asm_name!r} {' '.join(flags['asm-flags'])}"
    )
    run_command_log(f"ld -o {bin_name!r} {obj_name!r} {' '.join(flags['ld-flags'])}")

    return EXIT_OK


if __name__ == "__main__":
    assert main.__annotations__.get("return") is int, "main() should return an integer"

    filter_warnings("error", category=Warning)
    sys.exit(main())
